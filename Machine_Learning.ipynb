{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MACHINE LEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>body {\n",
       "    margin: 0;\n",
       "    font-family: Helvetica;\n",
       "}\n",
       "table.dataframe {\n",
       "    border-collapse: collapse;\n",
       "    border: none;\n",
       "}\n",
       "table.dataframe tr {\n",
       "    border: none;\n",
       "}\n",
       "table.dataframe td, table.dataframe th {\n",
       "    margin: 0;\n",
       "    border: 1px solid white;\n",
       "    padding-left: 0.25em;\n",
       "    padding-right: 0.25em;\n",
       "}\n",
       "table.dataframe th:not(:empty) {\n",
       "    background-color: #fec;\n",
       "    text-align: left;\n",
       "    font-weight: normal;\n",
       "}\n",
       "table.dataframe tr:nth-child(2) th:empty {\n",
       "    border-left: none;\n",
       "    border-right: 1px dashed #888;\n",
       "}\n",
       "table.dataframe td {\n",
       "    border: 2px solid #ccf;\n",
       "    background-color: #f4f4ff;\n",
       "}\n",
       "h3 {\n",
       "    color: white;\n",
       "    background-color: black;\n",
       "    padding: 0.5em;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "from IPython.core.display import HTML\n",
    "css = open('style-table.css').read() + open('style-notebook.css').read()\n",
    "HTML('<style>{}</style>'.format(css))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('lol_ml_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p1_champ</th>\n",
       "      <th>p2_champ</th>\n",
       "      <th>p3_champ</th>\n",
       "      <th>p4_champ</th>\n",
       "      <th>p5_champ</th>\n",
       "      <th>p6_champ</th>\n",
       "      <th>p7_champ</th>\n",
       "      <th>p8_champ</th>\n",
       "      <th>p9_champ</th>\n",
       "      <th>p10_champ</th>\n",
       "      <th>game_length_mins</th>\n",
       "      <th>blue_team_win</th>\n",
       "      <th>red_team_win</th>\n",
       "      <th>p1_spell1</th>\n",
       "      <th>p2_spell1</th>\n",
       "      <th>p3_spell1</th>\n",
       "      <th>p4_spell1</th>\n",
       "      <th>p5_spell1</th>\n",
       "      <th>p6_spell1</th>\n",
       "      <th>p7_spell1</th>\n",
       "      <th>p8_spell1</th>\n",
       "      <th>p9_spell1</th>\n",
       "      <th>p10_spell1</th>\n",
       "      <th>p1_spell2</th>\n",
       "      <th>p2_spell2</th>\n",
       "      <th>p3_spell2</th>\n",
       "      <th>p4_spell2</th>\n",
       "      <th>p5_spell2</th>\n",
       "      <th>p6_spell2</th>\n",
       "      <th>p7_spell2</th>\n",
       "      <th>p8_spell2</th>\n",
       "      <th>p9_spell2</th>\n",
       "      <th>p10_spell2</th>\n",
       "      <th>p1perkPrimaryStyle</th>\n",
       "      <th>p2perkPrimaryStyle</th>\n",
       "      <th>p3perkPrimaryStyle</th>\n",
       "      <th>p4perkPrimaryStyle</th>\n",
       "      <th>p5perkPrimaryStyle</th>\n",
       "      <th>p6perkPrimaryStyle</th>\n",
       "      <th>p7perkPrimaryStyle</th>\n",
       "      <th>p8perkPrimaryStyle</th>\n",
       "      <th>p9perkPrimaryStyle</th>\n",
       "      <th>p10perkPrimaryStyle</th>\n",
       "      <th>p1perkSubStyle</th>\n",
       "      <th>p2perkSubStyle</th>\n",
       "      <th>p3perkSubStyle</th>\n",
       "      <th>p4perkSubStyle</th>\n",
       "      <th>p5perkSubStyle</th>\n",
       "      <th>p6perkSubStyle</th>\n",
       "      <th>p7perkSubStyle</th>\n",
       "      <th>p8perkSubStyle</th>\n",
       "      <th>p9perkSubStyle</th>\n",
       "      <th>p10perkSubStyle</th>\n",
       "      <th>p1_champ_prim_role</th>\n",
       "      <th>p2_champ_prim_role</th>\n",
       "      <th>p3_champ_prim_role</th>\n",
       "      <th>p4_champ_prim_role</th>\n",
       "      <th>p5_champ_prim_role</th>\n",
       "      <th>p6_champ_prim_role</th>\n",
       "      <th>p7_champ_prim_role</th>\n",
       "      <th>p8_champ_prim_role</th>\n",
       "      <th>p9_champ_prim_role</th>\n",
       "      <th>p10_champ_prim_role</th>\n",
       "      <th>p1_champ_sec_role</th>\n",
       "      <th>p2_champ_sec_role</th>\n",
       "      <th>p3_champ_sec_role</th>\n",
       "      <th>p4_champ_sec_role</th>\n",
       "      <th>p5_champ_sec_role</th>\n",
       "      <th>p6_champ_sec_role</th>\n",
       "      <th>p7_champ_sec_role</th>\n",
       "      <th>p8_champ_sec_role</th>\n",
       "      <th>p9_champ_sec_role</th>\n",
       "      <th>p10_champ_sec_role</th>\n",
       "      <th>tank_count</th>\n",
       "      <th>mage_count</th>\n",
       "      <th>marksman_count</th>\n",
       "      <th>support_count</th>\n",
       "      <th>fighter_count</th>\n",
       "      <th>assassin_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Karma</td>\n",
       "      <td>Teemo</td>\n",
       "      <td>JarvanIV</td>\n",
       "      <td>Ezreal</td>\n",
       "      <td>Neeko</td>\n",
       "      <td>Ryze</td>\n",
       "      <td>Kaisa</td>\n",
       "      <td>Cassiopeia</td>\n",
       "      <td>Braum</td>\n",
       "      <td>Rengar</td>\n",
       "      <td>38.466667</td>\n",
       "      <td>Win</td>\n",
       "      <td>Fail</td>\n",
       "      <td>SummonerFlash</td>\n",
       "      <td>SummonerIgnite</td>\n",
       "      <td>SummonerFlash</td>\n",
       "      <td>SummonerFlash</td>\n",
       "      <td>SummonerFlash</td>\n",
       "      <td>SummonerTeleport</td>\n",
       "      <td>SummonerFlash</td>\n",
       "      <td>SummonerBoost</td>\n",
       "      <td>SummonerIgnite</td>\n",
       "      <td>SummonerFlash</td>\n",
       "      <td>SummonerIgnite</td>\n",
       "      <td>SummonerFlash</td>\n",
       "      <td>SummonerSmite</td>\n",
       "      <td>SummonerHeal</td>\n",
       "      <td>SummonerIgnite</td>\n",
       "      <td>SummonerFlash</td>\n",
       "      <td>SummonerHeal</td>\n",
       "      <td>SummonerFlash</td>\n",
       "      <td>SummonerFlash</td>\n",
       "      <td>SummonerSmite</td>\n",
       "      <td>Sorcery</td>\n",
       "      <td>Sorcery</td>\n",
       "      <td>Domination</td>\n",
       "      <td>Inspiration</td>\n",
       "      <td>Sorcery</td>\n",
       "      <td>Sorcery</td>\n",
       "      <td>Inspiration</td>\n",
       "      <td>Sorcery</td>\n",
       "      <td>Resolve</td>\n",
       "      <td>Domination</td>\n",
       "      <td>Inspiration</td>\n",
       "      <td>Domination</td>\n",
       "      <td>Inspiration</td>\n",
       "      <td>Sorcery</td>\n",
       "      <td>Domination</td>\n",
       "      <td>Domination</td>\n",
       "      <td>Sorcery</td>\n",
       "      <td>Domination</td>\n",
       "      <td>Inspiration</td>\n",
       "      <td>Sorcery</td>\n",
       "      <td>Mage</td>\n",
       "      <td>Marksman</td>\n",
       "      <td>Tank</td>\n",
       "      <td>Marksman</td>\n",
       "      <td>Mage</td>\n",
       "      <td>Mage</td>\n",
       "      <td>Marksman</td>\n",
       "      <td>Mage</td>\n",
       "      <td>Support</td>\n",
       "      <td>Assassin</td>\n",
       "      <td>Support</td>\n",
       "      <td>Assassin</td>\n",
       "      <td>Fighter</td>\n",
       "      <td>Mage</td>\n",
       "      <td>Support</td>\n",
       "      <td>Fighter</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Tank</td>\n",
       "      <td>Fighter</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Teemo</td>\n",
       "      <td>Tristana</td>\n",
       "      <td>LeeSin</td>\n",
       "      <td>Bard</td>\n",
       "      <td>Leblanc</td>\n",
       "      <td>Lucian</td>\n",
       "      <td>Irelia</td>\n",
       "      <td>Blitzcrank</td>\n",
       "      <td>Orianna</td>\n",
       "      <td>Kindred</td>\n",
       "      <td>23.400000</td>\n",
       "      <td>Win</td>\n",
       "      <td>Fail</td>\n",
       "      <td>SummonerFlash</td>\n",
       "      <td>SummonerFlash</td>\n",
       "      <td>SummonerFlash</td>\n",
       "      <td>SummonerFlash</td>\n",
       "      <td>SummonerIgnite</td>\n",
       "      <td>SummonerHeal</td>\n",
       "      <td>SummonerTeleport</td>\n",
       "      <td>SummonerIgnite</td>\n",
       "      <td>SummonerBarrier</td>\n",
       "      <td>SummonerFlash</td>\n",
       "      <td>SummonerIgnite</td>\n",
       "      <td>SummonerHeal</td>\n",
       "      <td>SummonerSmite</td>\n",
       "      <td>SummonerIgnite</td>\n",
       "      <td>SummonerFlash</td>\n",
       "      <td>SummonerFlash</td>\n",
       "      <td>SummonerFlash</td>\n",
       "      <td>SummonerFlash</td>\n",
       "      <td>SummonerFlash</td>\n",
       "      <td>SummonerSmite</td>\n",
       "      <td>Sorcery</td>\n",
       "      <td>Inspiration</td>\n",
       "      <td>Domination</td>\n",
       "      <td>Domination</td>\n",
       "      <td>Domination</td>\n",
       "      <td>Inspiration</td>\n",
       "      <td>Inspiration</td>\n",
       "      <td>Resolve</td>\n",
       "      <td>Sorcery</td>\n",
       "      <td>Inspiration</td>\n",
       "      <td>Resolve</td>\n",
       "      <td>Sorcery</td>\n",
       "      <td>Inspiration</td>\n",
       "      <td>Resolve</td>\n",
       "      <td>Sorcery</td>\n",
       "      <td>Sorcery</td>\n",
       "      <td>Sorcery</td>\n",
       "      <td>Inspiration</td>\n",
       "      <td>Inspiration</td>\n",
       "      <td>Domination</td>\n",
       "      <td>Marksman</td>\n",
       "      <td>Marksman</td>\n",
       "      <td>Fighter</td>\n",
       "      <td>Support</td>\n",
       "      <td>Assassin</td>\n",
       "      <td>Marksman</td>\n",
       "      <td>Fighter</td>\n",
       "      <td>Tank</td>\n",
       "      <td>Mage</td>\n",
       "      <td>Marksman</td>\n",
       "      <td>Assassin</td>\n",
       "      <td>Assassin</td>\n",
       "      <td>Assassin</td>\n",
       "      <td>Mage</td>\n",
       "      <td>Mage</td>\n",
       "      <td>None</td>\n",
       "      <td>Assassin</td>\n",
       "      <td>Fighter</td>\n",
       "      <td>Support</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JarvanIV</td>\n",
       "      <td>Lux</td>\n",
       "      <td>Zyra</td>\n",
       "      <td>Jax</td>\n",
       "      <td>Kaisa</td>\n",
       "      <td>Tryndamere</td>\n",
       "      <td>Ezreal</td>\n",
       "      <td>Thresh</td>\n",
       "      <td>Xerath</td>\n",
       "      <td>Karthus</td>\n",
       "      <td>31.733333</td>\n",
       "      <td>Fail</td>\n",
       "      <td>Win</td>\n",
       "      <td>SummonerFlash</td>\n",
       "      <td>SummonerFlash</td>\n",
       "      <td>SummonerTeleport</td>\n",
       "      <td>SummonerTeleport</td>\n",
       "      <td>SummonerFlash</td>\n",
       "      <td>SummonerIgnite</td>\n",
       "      <td>SummonerHeal</td>\n",
       "      <td>SummonerIgnite</td>\n",
       "      <td>SummonerHeal</td>\n",
       "      <td>SummonerSmite</td>\n",
       "      <td>SummonerSmite</td>\n",
       "      <td>SummonerIgnite</td>\n",
       "      <td>SummonerFlash</td>\n",
       "      <td>SummonerFlash</td>\n",
       "      <td>SummonerHeal</td>\n",
       "      <td>SummonerFlash</td>\n",
       "      <td>SummonerFlash</td>\n",
       "      <td>SummonerFlash</td>\n",
       "      <td>SummonerFlash</td>\n",
       "      <td>SummonerFlash</td>\n",
       "      <td>Domination</td>\n",
       "      <td>Sorcery</td>\n",
       "      <td>Sorcery</td>\n",
       "      <td>Inspiration</td>\n",
       "      <td>Inspiration</td>\n",
       "      <td>Inspiration</td>\n",
       "      <td>Inspiration</td>\n",
       "      <td>Resolve</td>\n",
       "      <td>Sorcery</td>\n",
       "      <td>Domination</td>\n",
       "      <td>Inspiration</td>\n",
       "      <td>Inspiration</td>\n",
       "      <td>Domination</td>\n",
       "      <td>Inspiration</td>\n",
       "      <td>Sorcery</td>\n",
       "      <td>Resolve</td>\n",
       "      <td>Sorcery</td>\n",
       "      <td>Inspiration</td>\n",
       "      <td>Inspiration</td>\n",
       "      <td>Inspiration</td>\n",
       "      <td>Tank</td>\n",
       "      <td>Mage</td>\n",
       "      <td>Mage</td>\n",
       "      <td>Fighter</td>\n",
       "      <td>Marksman</td>\n",
       "      <td>Fighter</td>\n",
       "      <td>Marksman</td>\n",
       "      <td>Support</td>\n",
       "      <td>Mage</td>\n",
       "      <td>Mage</td>\n",
       "      <td>Fighter</td>\n",
       "      <td>Support</td>\n",
       "      <td>Support</td>\n",
       "      <td>Assassin</td>\n",
       "      <td>None</td>\n",
       "      <td>Assassin</td>\n",
       "      <td>Mage</td>\n",
       "      <td>Fighter</td>\n",
       "      <td>Assassin</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Blitzcrank</td>\n",
       "      <td>Graves</td>\n",
       "      <td>Caitlyn</td>\n",
       "      <td>Kled</td>\n",
       "      <td>Diana</td>\n",
       "      <td>LeeSin</td>\n",
       "      <td>Lucian</td>\n",
       "      <td>Thresh</td>\n",
       "      <td>Lissandra</td>\n",
       "      <td>Urgot</td>\n",
       "      <td>35.366667</td>\n",
       "      <td>Win</td>\n",
       "      <td>Fail</td>\n",
       "      <td>SummonerIgnite</td>\n",
       "      <td>SummonerFlash</td>\n",
       "      <td>SummonerHeal</td>\n",
       "      <td>SummonerTeleport</td>\n",
       "      <td>SummonerFlash</td>\n",
       "      <td>SummonerFlash</td>\n",
       "      <td>SummonerHeal</td>\n",
       "      <td>SummonerFlash</td>\n",
       "      <td>SummonerTeleport</td>\n",
       "      <td>SummonerFlash</td>\n",
       "      <td>SummonerFlash</td>\n",
       "      <td>SummonerSmite</td>\n",
       "      <td>SummonerFlash</td>\n",
       "      <td>SummonerFlash</td>\n",
       "      <td>SummonerTeleport</td>\n",
       "      <td>SummonerSmite</td>\n",
       "      <td>SummonerFlash</td>\n",
       "      <td>SummonerIgnite</td>\n",
       "      <td>SummonerFlash</td>\n",
       "      <td>SummonerTeleport</td>\n",
       "      <td>Resolve</td>\n",
       "      <td>Inspiration</td>\n",
       "      <td>Inspiration</td>\n",
       "      <td>Inspiration</td>\n",
       "      <td>Sorcery</td>\n",
       "      <td>Domination</td>\n",
       "      <td>Inspiration</td>\n",
       "      <td>Resolve</td>\n",
       "      <td>Sorcery</td>\n",
       "      <td>Inspiration</td>\n",
       "      <td>Sorcery</td>\n",
       "      <td>Sorcery</td>\n",
       "      <td>Sorcery</td>\n",
       "      <td>Resolve</td>\n",
       "      <td>Domination</td>\n",
       "      <td>Inspiration</td>\n",
       "      <td>Sorcery</td>\n",
       "      <td>Inspiration</td>\n",
       "      <td>Inspiration</td>\n",
       "      <td>Resolve</td>\n",
       "      <td>Tank</td>\n",
       "      <td>Marksman</td>\n",
       "      <td>Marksman</td>\n",
       "      <td>Fighter</td>\n",
       "      <td>Fighter</td>\n",
       "      <td>Fighter</td>\n",
       "      <td>Marksman</td>\n",
       "      <td>Support</td>\n",
       "      <td>Mage</td>\n",
       "      <td>Fighter</td>\n",
       "      <td>Fighter</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Tank</td>\n",
       "      <td>Mage</td>\n",
       "      <td>Assassin</td>\n",
       "      <td>None</td>\n",
       "      <td>Fighter</td>\n",
       "      <td>None</td>\n",
       "      <td>Marksman</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lux</td>\n",
       "      <td>Jhin</td>\n",
       "      <td>Gragas</td>\n",
       "      <td>Fiora</td>\n",
       "      <td>Kindred</td>\n",
       "      <td>Tristana</td>\n",
       "      <td>Fiddlesticks</td>\n",
       "      <td>Graves</td>\n",
       "      <td>Xerath</td>\n",
       "      <td>Kennen</td>\n",
       "      <td>23.933333</td>\n",
       "      <td>Fail</td>\n",
       "      <td>Win</td>\n",
       "      <td>SummonerFlash</td>\n",
       "      <td>SummonerFlash</td>\n",
       "      <td>SummonerFlash</td>\n",
       "      <td>SummonerFlash</td>\n",
       "      <td>SummonerFlash</td>\n",
       "      <td>SummonerFlash</td>\n",
       "      <td>SummonerIgnite</td>\n",
       "      <td>SummonerFlash</td>\n",
       "      <td>SummonerFlash</td>\n",
       "      <td>SummonerTeleport</td>\n",
       "      <td>SummonerIgnite</td>\n",
       "      <td>SummonerHeal</td>\n",
       "      <td>SummonerIgnite</td>\n",
       "      <td>SummonerIgnite</td>\n",
       "      <td>SummonerSmite</td>\n",
       "      <td>SummonerHeal</td>\n",
       "      <td>SummonerFlash</td>\n",
       "      <td>SummonerSmite</td>\n",
       "      <td>SummonerBarrier</td>\n",
       "      <td>SummonerFlash</td>\n",
       "      <td>Domination</td>\n",
       "      <td>Inspiration</td>\n",
       "      <td>Resolve</td>\n",
       "      <td>Domination</td>\n",
       "      <td>Inspiration</td>\n",
       "      <td>Inspiration</td>\n",
       "      <td>Inspiration</td>\n",
       "      <td>Inspiration</td>\n",
       "      <td>Domination</td>\n",
       "      <td>Sorcery</td>\n",
       "      <td>Sorcery</td>\n",
       "      <td>Sorcery</td>\n",
       "      <td>Inspiration</td>\n",
       "      <td>Sorcery</td>\n",
       "      <td>Domination</td>\n",
       "      <td>Sorcery</td>\n",
       "      <td>Sorcery</td>\n",
       "      <td>Sorcery</td>\n",
       "      <td>Sorcery</td>\n",
       "      <td>Domination</td>\n",
       "      <td>Mage</td>\n",
       "      <td>Marksman</td>\n",
       "      <td>Fighter</td>\n",
       "      <td>Fighter</td>\n",
       "      <td>Marksman</td>\n",
       "      <td>Marksman</td>\n",
       "      <td>Mage</td>\n",
       "      <td>Marksman</td>\n",
       "      <td>Mage</td>\n",
       "      <td>Mage</td>\n",
       "      <td>Support</td>\n",
       "      <td>Assassin</td>\n",
       "      <td>Mage</td>\n",
       "      <td>Assassin</td>\n",
       "      <td>None</td>\n",
       "      <td>Assassin</td>\n",
       "      <td>Support</td>\n",
       "      <td>None</td>\n",
       "      <td>Assassin</td>\n",
       "      <td>Marksman</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     p1_champ  p2_champ  p3_champ p4_champ p5_champ    p6_champ      p7_champ  \\\n",
       "0       Karma     Teemo  JarvanIV   Ezreal    Neeko        Ryze         Kaisa   \n",
       "1       Teemo  Tristana    LeeSin     Bard  Leblanc      Lucian        Irelia   \n",
       "2    JarvanIV       Lux      Zyra      Jax    Kaisa  Tryndamere        Ezreal   \n",
       "3  Blitzcrank    Graves   Caitlyn     Kled    Diana      LeeSin        Lucian   \n",
       "4         Lux      Jhin    Gragas    Fiora  Kindred    Tristana  Fiddlesticks   \n",
       "\n",
       "     p8_champ   p9_champ p10_champ  game_length_mins blue_team_win  \\\n",
       "0  Cassiopeia      Braum    Rengar         38.466667           Win   \n",
       "1  Blitzcrank    Orianna   Kindred         23.400000           Win   \n",
       "2      Thresh     Xerath   Karthus         31.733333          Fail   \n",
       "3      Thresh  Lissandra     Urgot         35.366667           Win   \n",
       "4      Graves     Xerath    Kennen         23.933333          Fail   \n",
       "\n",
       "  red_team_win       p1_spell1       p2_spell1         p3_spell1  \\\n",
       "0         Fail   SummonerFlash  SummonerIgnite     SummonerFlash   \n",
       "1         Fail   SummonerFlash   SummonerFlash     SummonerFlash   \n",
       "2          Win   SummonerFlash   SummonerFlash  SummonerTeleport   \n",
       "3         Fail  SummonerIgnite   SummonerFlash      SummonerHeal   \n",
       "4          Win   SummonerFlash   SummonerFlash     SummonerFlash   \n",
       "\n",
       "          p4_spell1       p5_spell1         p6_spell1         p7_spell1  \\\n",
       "0     SummonerFlash   SummonerFlash  SummonerTeleport     SummonerFlash   \n",
       "1     SummonerFlash  SummonerIgnite      SummonerHeal  SummonerTeleport   \n",
       "2  SummonerTeleport   SummonerFlash    SummonerIgnite      SummonerHeal   \n",
       "3  SummonerTeleport   SummonerFlash     SummonerFlash      SummonerHeal   \n",
       "4     SummonerFlash   SummonerFlash     SummonerFlash    SummonerIgnite   \n",
       "\n",
       "        p8_spell1         p9_spell1        p10_spell1       p1_spell2  \\\n",
       "0   SummonerBoost    SummonerIgnite     SummonerFlash  SummonerIgnite   \n",
       "1  SummonerIgnite   SummonerBarrier     SummonerFlash  SummonerIgnite   \n",
       "2  SummonerIgnite      SummonerHeal     SummonerSmite   SummonerSmite   \n",
       "3   SummonerFlash  SummonerTeleport     SummonerFlash   SummonerFlash   \n",
       "4   SummonerFlash     SummonerFlash  SummonerTeleport  SummonerIgnite   \n",
       "\n",
       "        p2_spell2       p3_spell2       p4_spell2         p5_spell2  \\\n",
       "0   SummonerFlash   SummonerSmite    SummonerHeal    SummonerIgnite   \n",
       "1    SummonerHeal   SummonerSmite  SummonerIgnite     SummonerFlash   \n",
       "2  SummonerIgnite   SummonerFlash   SummonerFlash      SummonerHeal   \n",
       "3   SummonerSmite   SummonerFlash   SummonerFlash  SummonerTeleport   \n",
       "4    SummonerHeal  SummonerIgnite  SummonerIgnite     SummonerSmite   \n",
       "\n",
       "       p6_spell2      p7_spell2       p8_spell2        p9_spell2  \\\n",
       "0  SummonerFlash   SummonerHeal   SummonerFlash    SummonerFlash   \n",
       "1  SummonerFlash  SummonerFlash   SummonerFlash    SummonerFlash   \n",
       "2  SummonerFlash  SummonerFlash   SummonerFlash    SummonerFlash   \n",
       "3  SummonerSmite  SummonerFlash  SummonerIgnite    SummonerFlash   \n",
       "4   SummonerHeal  SummonerFlash   SummonerSmite  SummonerBarrier   \n",
       "\n",
       "         p10_spell2 p1perkPrimaryStyle p2perkPrimaryStyle p3perkPrimaryStyle  \\\n",
       "0     SummonerSmite            Sorcery            Sorcery         Domination   \n",
       "1     SummonerSmite            Sorcery        Inspiration         Domination   \n",
       "2     SummonerFlash         Domination            Sorcery            Sorcery   \n",
       "3  SummonerTeleport            Resolve        Inspiration        Inspiration   \n",
       "4     SummonerFlash         Domination        Inspiration            Resolve   \n",
       "\n",
       "  p4perkPrimaryStyle p5perkPrimaryStyle p6perkPrimaryStyle p7perkPrimaryStyle  \\\n",
       "0        Inspiration            Sorcery            Sorcery        Inspiration   \n",
       "1         Domination         Domination        Inspiration        Inspiration   \n",
       "2        Inspiration        Inspiration        Inspiration        Inspiration   \n",
       "3        Inspiration            Sorcery         Domination        Inspiration   \n",
       "4         Domination        Inspiration        Inspiration        Inspiration   \n",
       "\n",
       "  p8perkPrimaryStyle p9perkPrimaryStyle p10perkPrimaryStyle p1perkSubStyle  \\\n",
       "0            Sorcery            Resolve          Domination    Inspiration   \n",
       "1            Resolve            Sorcery         Inspiration        Resolve   \n",
       "2            Resolve            Sorcery          Domination    Inspiration   \n",
       "3            Resolve            Sorcery         Inspiration        Sorcery   \n",
       "4        Inspiration         Domination             Sorcery        Sorcery   \n",
       "\n",
       "  p2perkSubStyle p3perkSubStyle p4perkSubStyle p5perkSubStyle p6perkSubStyle  \\\n",
       "0     Domination    Inspiration        Sorcery     Domination     Domination   \n",
       "1        Sorcery    Inspiration        Resolve        Sorcery        Sorcery   \n",
       "2    Inspiration     Domination    Inspiration        Sorcery        Resolve   \n",
       "3        Sorcery        Sorcery        Resolve     Domination    Inspiration   \n",
       "4        Sorcery    Inspiration        Sorcery     Domination        Sorcery   \n",
       "\n",
       "  p7perkSubStyle p8perkSubStyle p9perkSubStyle p10perkSubStyle  \\\n",
       "0        Sorcery     Domination    Inspiration         Sorcery   \n",
       "1        Sorcery    Inspiration    Inspiration      Domination   \n",
       "2        Sorcery    Inspiration    Inspiration     Inspiration   \n",
       "3        Sorcery    Inspiration    Inspiration         Resolve   \n",
       "4        Sorcery        Sorcery        Sorcery      Domination   \n",
       "\n",
       "  p1_champ_prim_role p2_champ_prim_role p3_champ_prim_role p4_champ_prim_role  \\\n",
       "0               Mage           Marksman               Tank           Marksman   \n",
       "1           Marksman           Marksman            Fighter            Support   \n",
       "2               Tank               Mage               Mage            Fighter   \n",
       "3               Tank           Marksman           Marksman            Fighter   \n",
       "4               Mage           Marksman            Fighter            Fighter   \n",
       "\n",
       "  p5_champ_prim_role p6_champ_prim_role p7_champ_prim_role p8_champ_prim_role  \\\n",
       "0               Mage               Mage           Marksman               Mage   \n",
       "1           Assassin           Marksman            Fighter               Tank   \n",
       "2           Marksman            Fighter           Marksman            Support   \n",
       "3            Fighter            Fighter           Marksman            Support   \n",
       "4           Marksman           Marksman               Mage           Marksman   \n",
       "\n",
       "  p9_champ_prim_role p10_champ_prim_role p1_champ_sec_role p2_champ_sec_role  \\\n",
       "0            Support            Assassin           Support          Assassin   \n",
       "1               Mage            Marksman          Assassin          Assassin   \n",
       "2               Mage                Mage           Fighter           Support   \n",
       "3               Mage             Fighter           Fighter              None   \n",
       "4               Mage                Mage           Support          Assassin   \n",
       "\n",
       "  p3_champ_sec_role p4_champ_sec_role p5_champ_sec_role p6_champ_sec_role  \\\n",
       "0           Fighter              Mage           Support           Fighter   \n",
       "1          Assassin              Mage              Mage              None   \n",
       "2           Support          Assassin              None          Assassin   \n",
       "3              None              Tank              Mage          Assassin   \n",
       "4              Mage          Assassin              None          Assassin   \n",
       "\n",
       "  p7_champ_sec_role p8_champ_sec_role p9_champ_sec_role p10_champ_sec_role  \\\n",
       "0              None              None              Tank            Fighter   \n",
       "1          Assassin           Fighter           Support               None   \n",
       "2              Mage           Fighter          Assassin               None   \n",
       "3              None           Fighter              None           Marksman   \n",
       "4           Support              None          Assassin           Marksman   \n",
       "\n",
       "   tank_count  mage_count  marksman_count  support_count  fighter_count  \\\n",
       "0           2           5               3              3              3   \n",
       "1           1           3               4              2              3   \n",
       "2           1           5               2              3              4   \n",
       "3           2           2               4              1              6   \n",
       "4           0           5               5              2              2   \n",
       "\n",
       "   assassin_count  \n",
       "0               2  \n",
       "1               5  \n",
       "2               3  \n",
       "3               1  \n",
       "4               4  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#the data we want to predict\n",
    "red_win = df['red_team_win'].values\n",
    "blue_win = df['blue_team_win'].values\n",
    "game_length = df['game_length_mins'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Fail', 'Fail', 'Win', 'Fail', 'Win'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_win[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create features\n",
    "X = df.drop(['red_team_win', 'blue_team_win', 'game_length_mins'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create a list of the categorical features\n",
    "col_list = X.columns.tolist()\n",
    "cat_feat = col_list[:-6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create dummy variables for categorical features\n",
    "X = pd.get_dummies(X, columns=cat_feat, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Random Forest model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's test a Random Forest Classifier out of the box with out hyper parameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, red_win, test_size=0.2, random_state=42)\n",
    "#rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the accuracy score for our Random Forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8074592890912274"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Win', 'Fail', 'Win', ..., 'Win', 'Fail', 'Fail'], dtype=object)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = rf.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Fail       0.79      0.86      0.82     14336\n",
      "        Win       0.84      0.77      0.80     14219\n",
      "\n",
      "avg / total       0.82      0.81      0.81     28555\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#CLassification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation for the Random Forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92365878 0.95885134 0.86366183 0.65612524 0.67160468]\n"
     ]
    }
   ],
   "source": [
    "#Does cross_val_score fit the model and save the fitted model to rf2?\n",
    "rf2 = RandomForestClassifier()\n",
    "cv_rf_results = cross_val_score(rf2, X, red_win, cv=5)\n",
    "print(cv_rf_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8147803728451987"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the mean score of the cross validation\n",
    "np.mean(cv_rf_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try out of the box Random Forest Model again and scaling the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up pipeline\n",
    "steps = [('scaler', StandardScaler()),\n",
    "        ('rforest', RandomForestClassifier())]\n",
    "\n",
    "pl = Pipeline(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Cross validation\n",
    "scaled_cv_rf_results = cross_val_score(pl, X, red_win, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92505953 0.95766065 0.86124536 0.6562303  0.67412622]\n"
     ]
    }
   ],
   "source": [
    "print(scaled_cv_rf_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8148644128337945\n"
     ]
    }
   ],
   "source": [
    "cv_score = np.mean(scaled_cv_rf_results)\n",
    "print(cv_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By scaling the features, we get slightly better performance from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('rforest', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       " ...n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pl_predict = pl.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Fail       0.79      0.86      0.82     14336\n",
      "        Win       0.84      0.77      0.80     14219\n",
      "\n",
      "avg / total       0.81      0.81      0.81     28555\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pl_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparamter Tuning the Random Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf3 = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#default hyperparameters\n",
    "rf3.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_estimators = [int(x) for x in np.linspace(start=10, stop=100, num=10)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 3, 5, 10]\n",
    "min_samples_leaf = [1, 2, 3, 4]\n",
    "bootstrap = [True, False]\n",
    "\n",
    "param_grid = {'n_estimators': n_estimators,\n",
    "              'max_features': max_features,\n",
    "              'max_depth': max_depth,\n",
    "              'min_samples_split': min_samples_split,\n",
    "              'min_samples_leaf': min_samples_leaf,\n",
    "              'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Use RandomizedSearchCV to see if we can get estimate of better hyperparameters\n",
    "#n_jobs set to 2?\n",
    "#cv set to 3?\n",
    "# Take a smaller subset of the data to split into training and testing\n",
    "# for finding hyper parameters, maybe 20k games\n",
    "\n",
    "#Takes about an hour to run on the full training set\n",
    "#rf_rand_cv = RandomizedSearchCV(estimator=rf3, param_distributions=param_grid,\n",
    "#                                cv=5, n_iter=10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_rand_cv = RandomizedSearchCV(estimator=rf3, param_distributions=param_grid,\n",
    "                                cv=3, n_iter=10, n_jobs=2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise',\n",
       "          estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "          fit_params=None, iid=True, n_iter=10, n_jobs=1,\n",
       "          param_distributions={'n_estimators': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 3, 5, 10], 'min_samples_leaf': [1, 2, 3, 4], 'bootstrap': [True, False]},\n",
       "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=0)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_rand_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': False,\n",
       " 'max_depth': 80,\n",
       " 'max_features': 'sqrt',\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 5,\n",
       " 'n_estimators': 60}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find best hyperparameters\n",
    "rf_rand_cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BEST MODEL SO FAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92810618 0.95937664 0.86849478 0.66232402 0.68120053]\n"
     ]
    }
   ],
   "source": [
    "#Use best hyperparamters and cross validate score\n",
    "#BEST MODEL SO FAR\n",
    "rf4 = RandomForestClassifier(bootstrap=True,\n",
    "                                max_depth=80, max_features='sqrt',\n",
    "                                min_samples_leaf=1, min_samples_split=5,\n",
    "                                n_estimators=60)\n",
    "\n",
    "cv_rf_results_params = cross_val_score(rf4, X, red_win, cv=5)\n",
    "\n",
    "print(cv_rf_results_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8199004301394114\n"
     ]
    }
   ],
   "source": [
    "cv_score2 = np.mean(cv_rf_results_params)\n",
    "print(cv_score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the current hyperparameters above increased the accuracy of the model by 0.00504%\n"
     ]
    }
   ],
   "source": [
    "#Find improvement with tuned hyperparameters\n",
    "diff = cv_score2 - 0.8148644128337945\n",
    "print(f'Using the current hyperparameters above increased the accuracy of the model by {diff:.5f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=80, max_features='sqrt', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=60, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf4.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pickle the model\n",
    "#file_name = 'rf_model_best.pickle'\n",
    "#with open('ML_models\\\\'+file_name, 'wb') as file:\n",
    "#    pickle.dump(rf4, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf4_predict = rf4.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Fail       0.82      0.82      0.82     14336\n",
      "        Win       0.82      0.81      0.82     14219\n",
      "\n",
      "avg / total       0.82      0.82      0.82     28555\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification Report\n",
    "print(classification_report(y_test, rf4_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute predicted probabilities of wins\n",
    "rf4_predict_proba = rf4.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Generate ROC curve values\n",
    "fpr, tpr, thresholds = roc_curve(y_test, rf4_predict_proba, pos_label='Win')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot ROC curve\n",
    "plt.plot([0,1], [0,1], 'k--')\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Further Tuning of hyperparameters using a smaller training subset due to time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Random 20,000 rows of df\n",
    "df_subset = df.sample(20000, random_state=42)\n",
    "subset_red_win = df_subset['red_team_win'].values\n",
    "subset_blue_win = df_subset['blue_team_win'].values\n",
    "subset_game_length = df_subset['game_length_mins'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_subset = df_subset.drop(['red_team_win', 'blue_team_win', 'game_length_mins'], axis=1)\n",
    "X_subset = pd.get_dummies(X_subset, columns=cat_feat, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_subset, subset_red_win,\n",
    "                                                       test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tighter parameter grid\n",
    "param_grid2 = {'n_estimators': [58, 59, 60, 61, 62],\n",
    "              'max_features': ['sqrt'],\n",
    "              'max_depth': [78, 79, 80, 81, 82],\n",
    "              'min_samples_split': [3, 4, 5, 6, 9, 10],\n",
    "              'min_samples_leaf': [1, 2, 3],\n",
    "              'bootstrap': [True, False]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf5 = RandomForestClassifier()\n",
    "rf_grid_cv = GridSearchCV(estimator=rf5, param_grid=param_grid2,\n",
    "                                cv=3, n_jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=2,\n",
       "       param_grid={'n_estimators': [58, 59, 60, 61, 62], 'max_features': ['sqrt'], 'max_depth': [78, 79, 80, 81, 82], 'min_samples_split': [3, 4, 5, 6, 9, 10], 'min_samples_leaf': [1, 2, 3], 'bootstrap': [True, False]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_grid_cv.fit(X_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'max_depth': 79,\n",
       " 'max_features': 'sqrt',\n",
       " 'min_samples_leaf': 3,\n",
       " 'min_samples_split': 4,\n",
       " 'n_estimators': 58}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Best estimator from the grid search\n",
    "rf_grid_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6790054281211697"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_grid_cv.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Try searching for better hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set N_iter to 25 to see if we can get better hyper paramters\n",
    "rf_rand_cv_25 = RandomizedSearchCV(estimator=rf, param_distributions=param_grid,\n",
    "                                cv=5, n_iter=25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise',\n",
       "          estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "          fit_params=None, iid=True, n_iter=25, n_jobs=1,\n",
       "          param_distributions={'n_estimators': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 3, 5, 10], 'min_samples_leaf': [1, 2, 3, 4], 'bootstrap': [True, False]},\n",
       "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_rand_cv_25.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': False,\n",
       " 'max_depth': 60,\n",
       " 'max_features': 'auto',\n",
       " 'min_samples_leaf': 4,\n",
       " 'min_samples_split': 3,\n",
       " 'n_estimators': 90}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_rand_cv_25.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pickle the model\n",
    "#file_name = 'rf_model_1.pickle'\n",
    "#with open('ML_models\\\\'+file_name, 'wb') as file:\n",
    "#    pickle.dump(rf_rand_cv_25, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7890612688017651"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_rand_cv_25.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jltsa\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\jltsa\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\jltsa\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\jltsa\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\jltsa\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\jltsa\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\jltsa\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "results_rf = pd.DataFrame(rf_rand_cv_25.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_bootstrap</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.161432</td>\n",
       "      <td>0.358706</td>\n",
       "      <td>0.417631</td>\n",
       "      <td>0.011522</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>110</td>\n",
       "      <td>False</td>\n",
       "      <td>{'n_estimators': 10, 'min_samples_split': 10, ...</td>\n",
       "      <td>0.781649</td>\n",
       "      <td>0.786202</td>\n",
       "      <td>0.787559</td>\n",
       "      <td>0.784485</td>\n",
       "      <td>0.776387</td>\n",
       "      <td>0.783257</td>\n",
       "      <td>0.003962</td>\n",
       "      <td>15</td>\n",
       "      <td>0.997395</td>\n",
       "      <td>0.997176</td>\n",
       "      <td>0.997231</td>\n",
       "      <td>0.997538</td>\n",
       "      <td>0.997341</td>\n",
       "      <td>0.997336</td>\n",
       "      <td>0.000127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69.548541</td>\n",
       "      <td>1.746423</td>\n",
       "      <td>0.806370</td>\n",
       "      <td>0.018504</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>{'n_estimators': 40, 'min_samples_split': 2, '...</td>\n",
       "      <td>0.784933</td>\n",
       "      <td>0.786684</td>\n",
       "      <td>0.788697</td>\n",
       "      <td>0.785448</td>\n",
       "      <td>0.779845</td>\n",
       "      <td>0.785121</td>\n",
       "      <td>0.002940</td>\n",
       "      <td>9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.740825</td>\n",
       "      <td>0.095760</td>\n",
       "      <td>0.346635</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>30</td>\n",
       "      <td>True</td>\n",
       "      <td>{'n_estimators': 10, 'min_samples_split': 5, '...</td>\n",
       "      <td>0.694055</td>\n",
       "      <td>0.689590</td>\n",
       "      <td>0.689109</td>\n",
       "      <td>0.694129</td>\n",
       "      <td>0.693823</td>\n",
       "      <td>0.692141</td>\n",
       "      <td>0.002287</td>\n",
       "      <td>24</td>\n",
       "      <td>0.840939</td>\n",
       "      <td>0.832086</td>\n",
       "      <td>0.825705</td>\n",
       "      <td>0.838096</td>\n",
       "      <td>0.841707</td>\n",
       "      <td>0.835707</td>\n",
       "      <td>0.006037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.949662</td>\n",
       "      <td>0.249374</td>\n",
       "      <td>0.384508</td>\n",
       "      <td>0.006001</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "      <td>{'n_estimators': 10, 'min_samples_split': 10, ...</td>\n",
       "      <td>0.767598</td>\n",
       "      <td>0.763264</td>\n",
       "      <td>0.767554</td>\n",
       "      <td>0.768901</td>\n",
       "      <td>0.766187</td>\n",
       "      <td>0.766701</td>\n",
       "      <td>0.001921</td>\n",
       "      <td>19</td>\n",
       "      <td>0.969324</td>\n",
       "      <td>0.964104</td>\n",
       "      <td>0.959792</td>\n",
       "      <td>0.966227</td>\n",
       "      <td>0.966194</td>\n",
       "      <td>0.965128</td>\n",
       "      <td>0.003146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90.972121</td>\n",
       "      <td>2.569169</td>\n",
       "      <td>1.001722</td>\n",
       "      <td>0.052421</td>\n",
       "      <td>70</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "      <td>{'n_estimators': 70, 'min_samples_split': 5, '...</td>\n",
       "      <td>0.784276</td>\n",
       "      <td>0.786640</td>\n",
       "      <td>0.786333</td>\n",
       "      <td>0.787112</td>\n",
       "      <td>0.785142</td>\n",
       "      <td>0.785901</td>\n",
       "      <td>0.001041</td>\n",
       "      <td>5</td>\n",
       "      <td>0.999934</td>\n",
       "      <td>0.999902</td>\n",
       "      <td>0.999934</td>\n",
       "      <td>0.999945</td>\n",
       "      <td>0.999869</td>\n",
       "      <td>0.999917</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>27.566918</td>\n",
       "      <td>0.260747</td>\n",
       "      <td>0.490514</td>\n",
       "      <td>0.012507</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>auto</td>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "      <td>{'n_estimators': 20, 'min_samples_split': 10, ...</td>\n",
       "      <td>0.781255</td>\n",
       "      <td>0.782087</td>\n",
       "      <td>0.788697</td>\n",
       "      <td>0.786543</td>\n",
       "      <td>0.780458</td>\n",
       "      <td>0.783808</td>\n",
       "      <td>0.003228</td>\n",
       "      <td>12</td>\n",
       "      <td>0.995163</td>\n",
       "      <td>0.992733</td>\n",
       "      <td>0.994419</td>\n",
       "      <td>0.995272</td>\n",
       "      <td>0.994462</td>\n",
       "      <td>0.994410</td>\n",
       "      <td>0.000908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>35.808305</td>\n",
       "      <td>0.516323</td>\n",
       "      <td>0.648543</td>\n",
       "      <td>0.006390</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>{'n_estimators': 30, 'min_samples_split': 3, '...</td>\n",
       "      <td>0.784101</td>\n",
       "      <td>0.779942</td>\n",
       "      <td>0.783970</td>\n",
       "      <td>0.781990</td>\n",
       "      <td>0.780108</td>\n",
       "      <td>0.782022</td>\n",
       "      <td>0.001795</td>\n",
       "      <td>17</td>\n",
       "      <td>0.992361</td>\n",
       "      <td>0.993226</td>\n",
       "      <td>0.992525</td>\n",
       "      <td>0.992777</td>\n",
       "      <td>0.992810</td>\n",
       "      <td>0.992740</td>\n",
       "      <td>0.000294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>36.406998</td>\n",
       "      <td>0.354982</td>\n",
       "      <td>0.672647</td>\n",
       "      <td>0.008480</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>{'n_estimators': 30, 'min_samples_split': 3, '...</td>\n",
       "      <td>0.781212</td>\n",
       "      <td>0.782481</td>\n",
       "      <td>0.786902</td>\n",
       "      <td>0.783654</td>\n",
       "      <td>0.781509</td>\n",
       "      <td>0.783152</td>\n",
       "      <td>0.002061</td>\n",
       "      <td>16</td>\n",
       "      <td>0.998293</td>\n",
       "      <td>0.998369</td>\n",
       "      <td>0.998337</td>\n",
       "      <td>0.998161</td>\n",
       "      <td>0.998304</td>\n",
       "      <td>0.998293</td>\n",
       "      <td>0.000071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>73.650992</td>\n",
       "      <td>1.272277</td>\n",
       "      <td>0.828861</td>\n",
       "      <td>0.010074</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>{'n_estimators': 50, 'min_samples_split': 3, '...</td>\n",
       "      <td>0.783225</td>\n",
       "      <td>0.788172</td>\n",
       "      <td>0.789135</td>\n",
       "      <td>0.787287</td>\n",
       "      <td>0.784573</td>\n",
       "      <td>0.786478</td>\n",
       "      <td>0.002227</td>\n",
       "      <td>3</td>\n",
       "      <td>0.999573</td>\n",
       "      <td>0.999639</td>\n",
       "      <td>0.999661</td>\n",
       "      <td>0.999628</td>\n",
       "      <td>0.999661</td>\n",
       "      <td>0.999632</td>\n",
       "      <td>0.000032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>105.907686</td>\n",
       "      <td>1.010205</td>\n",
       "      <td>1.094454</td>\n",
       "      <td>0.008458</td>\n",
       "      <td>60</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>80</td>\n",
       "      <td>False</td>\n",
       "      <td>{'n_estimators': 60, 'min_samples_split': 5, '...</td>\n",
       "      <td>0.783926</td>\n",
       "      <td>0.785064</td>\n",
       "      <td>0.789398</td>\n",
       "      <td>0.785186</td>\n",
       "      <td>0.784267</td>\n",
       "      <td>0.785568</td>\n",
       "      <td>0.001973</td>\n",
       "      <td>8</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>24.672145</td>\n",
       "      <td>0.361100</td>\n",
       "      <td>0.549872</td>\n",
       "      <td>0.011676</td>\n",
       "      <td>70</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>auto</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "      <td>{'n_estimators': 70, 'min_samples_split': 5, '...</td>\n",
       "      <td>0.708151</td>\n",
       "      <td>0.717606</td>\n",
       "      <td>0.716424</td>\n",
       "      <td>0.710852</td>\n",
       "      <td>0.707700</td>\n",
       "      <td>0.712147</td>\n",
       "      <td>0.004136</td>\n",
       "      <td>23</td>\n",
       "      <td>0.865410</td>\n",
       "      <td>0.869164</td>\n",
       "      <td>0.865968</td>\n",
       "      <td>0.864394</td>\n",
       "      <td>0.862599</td>\n",
       "      <td>0.865507</td>\n",
       "      <td>0.002158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>68.402390</td>\n",
       "      <td>0.932006</td>\n",
       "      <td>0.792255</td>\n",
       "      <td>0.011270</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "      <td>{'n_estimators': 50, 'min_samples_split': 3, '...</td>\n",
       "      <td>0.785151</td>\n",
       "      <td>0.785108</td>\n",
       "      <td>0.789135</td>\n",
       "      <td>0.786105</td>\n",
       "      <td>0.783172</td>\n",
       "      <td>0.785734</td>\n",
       "      <td>0.001949</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999978</td>\n",
       "      <td>0.999978</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>35.473977</td>\n",
       "      <td>0.756323</td>\n",
       "      <td>0.560187</td>\n",
       "      <td>0.006954</td>\n",
       "      <td>70</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "      <td>{'n_estimators': 70, 'min_samples_split': 5, '...</td>\n",
       "      <td>0.745229</td>\n",
       "      <td>0.743302</td>\n",
       "      <td>0.743171</td>\n",
       "      <td>0.744998</td>\n",
       "      <td>0.743641</td>\n",
       "      <td>0.744068</td>\n",
       "      <td>0.000870</td>\n",
       "      <td>22</td>\n",
       "      <td>0.923545</td>\n",
       "      <td>0.918631</td>\n",
       "      <td>0.920907</td>\n",
       "      <td>0.924761</td>\n",
       "      <td>0.917680</td>\n",
       "      <td>0.921105</td>\n",
       "      <td>0.002728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>133.308935</td>\n",
       "      <td>0.627465</td>\n",
       "      <td>1.261538</td>\n",
       "      <td>0.007543</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>auto</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>{'n_estimators': 90, 'min_samples_split': 3, '...</td>\n",
       "      <td>0.787034</td>\n",
       "      <td>0.785151</td>\n",
       "      <td>0.795045</td>\n",
       "      <td>0.791402</td>\n",
       "      <td>0.786674</td>\n",
       "      <td>0.789061</td>\n",
       "      <td>0.003644</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999956</td>\n",
       "      <td>0.999978</td>\n",
       "      <td>0.999978</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999978</td>\n",
       "      <td>0.999978</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>34.532558</td>\n",
       "      <td>0.257371</td>\n",
       "      <td>0.535150</td>\n",
       "      <td>0.006053</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>auto</td>\n",
       "      <td>80</td>\n",
       "      <td>False</td>\n",
       "      <td>{'n_estimators': 20, 'min_samples_split': 10, ...</td>\n",
       "      <td>0.782394</td>\n",
       "      <td>0.781606</td>\n",
       "      <td>0.785064</td>\n",
       "      <td>0.784223</td>\n",
       "      <td>0.789388</td>\n",
       "      <td>0.784535</td>\n",
       "      <td>0.002724</td>\n",
       "      <td>11</td>\n",
       "      <td>0.997001</td>\n",
       "      <td>0.996443</td>\n",
       "      <td>0.996826</td>\n",
       "      <td>0.996969</td>\n",
       "      <td>0.996465</td>\n",
       "      <td>0.996741</td>\n",
       "      <td>0.000242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>59.417172</td>\n",
       "      <td>0.362546</td>\n",
       "      <td>0.901635</td>\n",
       "      <td>0.007614</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>110</td>\n",
       "      <td>True</td>\n",
       "      <td>{'n_estimators': 50, 'min_samples_split': 2, '...</td>\n",
       "      <td>0.783751</td>\n",
       "      <td>0.789441</td>\n",
       "      <td>0.788960</td>\n",
       "      <td>0.787287</td>\n",
       "      <td>0.778663</td>\n",
       "      <td>0.785620</td>\n",
       "      <td>0.004011</td>\n",
       "      <td>7</td>\n",
       "      <td>0.998468</td>\n",
       "      <td>0.998347</td>\n",
       "      <td>0.998238</td>\n",
       "      <td>0.998490</td>\n",
       "      <td>0.998337</td>\n",
       "      <td>0.998376</td>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>23.694205</td>\n",
       "      <td>0.194392</td>\n",
       "      <td>0.524894</td>\n",
       "      <td>0.007656</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>{'n_estimators': 20, 'min_samples_split': 3, '...</td>\n",
       "      <td>0.764052</td>\n",
       "      <td>0.765278</td>\n",
       "      <td>0.770749</td>\n",
       "      <td>0.767281</td>\n",
       "      <td>0.768069</td>\n",
       "      <td>0.767086</td>\n",
       "      <td>0.002320</td>\n",
       "      <td>18</td>\n",
       "      <td>0.967015</td>\n",
       "      <td>0.968022</td>\n",
       "      <td>0.967398</td>\n",
       "      <td>0.966731</td>\n",
       "      <td>0.967551</td>\n",
       "      <td>0.967343</td>\n",
       "      <td>0.000445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>117.173346</td>\n",
       "      <td>2.500943</td>\n",
       "      <td>1.522172</td>\n",
       "      <td>0.007235</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>auto</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>{'n_estimators': 100, 'min_samples_split': 10,...</td>\n",
       "      <td>0.788347</td>\n",
       "      <td>0.780993</td>\n",
       "      <td>0.790142</td>\n",
       "      <td>0.790089</td>\n",
       "      <td>0.784223</td>\n",
       "      <td>0.786759</td>\n",
       "      <td>0.003598</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2.998356</td>\n",
       "      <td>0.046134</td>\n",
       "      <td>0.312444</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>{'n_estimators': 10, 'min_samples_split': 3, '...</td>\n",
       "      <td>0.554019</td>\n",
       "      <td>0.545088</td>\n",
       "      <td>0.552399</td>\n",
       "      <td>0.552073</td>\n",
       "      <td>0.541698</td>\n",
       "      <td>0.549055</td>\n",
       "      <td>0.004791</td>\n",
       "      <td>25</td>\n",
       "      <td>0.589347</td>\n",
       "      <td>0.584214</td>\n",
       "      <td>0.584860</td>\n",
       "      <td>0.580815</td>\n",
       "      <td>0.575103</td>\n",
       "      <td>0.582868</td>\n",
       "      <td>0.004739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>58.227889</td>\n",
       "      <td>1.040998</td>\n",
       "      <td>0.930667</td>\n",
       "      <td>0.046835</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>60</td>\n",
       "      <td>True</td>\n",
       "      <td>{'n_estimators': 60, 'min_samples_split': 2, '...</td>\n",
       "      <td>0.783619</td>\n",
       "      <td>0.780424</td>\n",
       "      <td>0.787909</td>\n",
       "      <td>0.783654</td>\n",
       "      <td>0.781202</td>\n",
       "      <td>0.783362</td>\n",
       "      <td>0.002613</td>\n",
       "      <td>13</td>\n",
       "      <td>0.996640</td>\n",
       "      <td>0.995666</td>\n",
       "      <td>0.996279</td>\n",
       "      <td>0.996651</td>\n",
       "      <td>0.996104</td>\n",
       "      <td>0.996268</td>\n",
       "      <td>0.000367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>127.591188</td>\n",
       "      <td>2.906488</td>\n",
       "      <td>1.219412</td>\n",
       "      <td>0.016336</td>\n",
       "      <td>70</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>{'n_estimators': 70, 'min_samples_split': 10, ...</td>\n",
       "      <td>0.784976</td>\n",
       "      <td>0.784539</td>\n",
       "      <td>0.789879</td>\n",
       "      <td>0.786280</td>\n",
       "      <td>0.786543</td>\n",
       "      <td>0.786443</td>\n",
       "      <td>0.001877</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>56.720910</td>\n",
       "      <td>1.328516</td>\n",
       "      <td>0.863201</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>auto</td>\n",
       "      <td>30</td>\n",
       "      <td>True</td>\n",
       "      <td>{'n_estimators': 100, 'min_samples_split': 2, ...</td>\n",
       "      <td>0.756216</td>\n",
       "      <td>0.763133</td>\n",
       "      <td>0.764971</td>\n",
       "      <td>0.762072</td>\n",
       "      <td>0.756599</td>\n",
       "      <td>0.760598</td>\n",
       "      <td>0.003547</td>\n",
       "      <td>21</td>\n",
       "      <td>0.954976</td>\n",
       "      <td>0.950139</td>\n",
       "      <td>0.951332</td>\n",
       "      <td>0.952109</td>\n",
       "      <td>0.951234</td>\n",
       "      <td>0.951958</td>\n",
       "      <td>0.001634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.564362</td>\n",
       "      <td>0.235175</td>\n",
       "      <td>0.524089</td>\n",
       "      <td>0.009086</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>auto</td>\n",
       "      <td>80</td>\n",
       "      <td>True</td>\n",
       "      <td>{'n_estimators': 20, 'min_samples_split': 10, ...</td>\n",
       "      <td>0.761863</td>\n",
       "      <td>0.758405</td>\n",
       "      <td>0.768604</td>\n",
       "      <td>0.763954</td>\n",
       "      <td>0.759095</td>\n",
       "      <td>0.762384</td>\n",
       "      <td>0.003690</td>\n",
       "      <td>20</td>\n",
       "      <td>0.960087</td>\n",
       "      <td>0.959879</td>\n",
       "      <td>0.958019</td>\n",
       "      <td>0.960668</td>\n",
       "      <td>0.961007</td>\n",
       "      <td>0.959932</td>\n",
       "      <td>0.001038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>34.027908</td>\n",
       "      <td>0.537623</td>\n",
       "      <td>0.551612</td>\n",
       "      <td>0.011699</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>{'n_estimators': 20, 'min_samples_split': 3, '...</td>\n",
       "      <td>0.783926</td>\n",
       "      <td>0.783444</td>\n",
       "      <td>0.787515</td>\n",
       "      <td>0.782253</td>\n",
       "      <td>0.787944</td>\n",
       "      <td>0.785016</td>\n",
       "      <td>0.002285</td>\n",
       "      <td>10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>39.797155</td>\n",
       "      <td>0.573473</td>\n",
       "      <td>0.577996</td>\n",
       "      <td>0.009883</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>{'n_estimators': 20, 'min_samples_split': 5, '...</td>\n",
       "      <td>0.781649</td>\n",
       "      <td>0.785764</td>\n",
       "      <td>0.787209</td>\n",
       "      <td>0.782209</td>\n",
       "      <td>0.779845</td>\n",
       "      <td>0.783335</td>\n",
       "      <td>0.002728</td>\n",
       "      <td>14</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       18.161432      0.358706         0.417631        0.011522   \n",
       "1       69.548541      1.746423         0.806370        0.018504   \n",
       "2        6.740825      0.095760         0.346635        0.007000   \n",
       "3       13.949662      0.249374         0.384508        0.006001   \n",
       "4       90.972121      2.569169         1.001722        0.052421   \n",
       "5       27.566918      0.260747         0.490514        0.012507   \n",
       "6       35.808305      0.516323         0.648543        0.006390   \n",
       "7       36.406998      0.354982         0.672647        0.008480   \n",
       "8       73.650992      1.272277         0.828861        0.010074   \n",
       "9      105.907686      1.010205         1.094454        0.008458   \n",
       "10      24.672145      0.361100         0.549872        0.011676   \n",
       "11      68.402390      0.932006         0.792255        0.011270   \n",
       "12      35.473977      0.756323         0.560187        0.006954   \n",
       "13     133.308935      0.627465         1.261538        0.007543   \n",
       "14      34.532558      0.257371         0.535150        0.006053   \n",
       "15      59.417172      0.362546         0.901635        0.007614   \n",
       "16      23.694205      0.194392         0.524894        0.007656   \n",
       "17     117.173346      2.500943         1.522172        0.007235   \n",
       "18       2.998356      0.046134         0.312444        0.000016   \n",
       "19      58.227889      1.040998         0.930667        0.046835   \n",
       "20     127.591188      2.906488         1.219412        0.016336   \n",
       "21      56.720910      1.328516         0.863201        0.006061   \n",
       "22      23.564362      0.235175         0.524089        0.009086   \n",
       "23      34.027908      0.537623         0.551612        0.011699   \n",
       "24      39.797155      0.573473         0.577996        0.009883   \n",
       "\n",
       "   param_n_estimators param_min_samples_split param_min_samples_leaf  \\\n",
       "0                  10                      10                      2   \n",
       "1                  40                       2                      3   \n",
       "2                  10                       5                      2   \n",
       "3                  10                      10                      3   \n",
       "4                  70                       5                      3   \n",
       "5                  20                      10                      2   \n",
       "6                  30                       3                      3   \n",
       "7                  30                       3                      2   \n",
       "8                  50                       3                      4   \n",
       "9                  60                       5                      1   \n",
       "10                 70                       5                      4   \n",
       "11                 50                       3                      2   \n",
       "12                 70                       5                      3   \n",
       "13                 90                       3                      4   \n",
       "14                 20                      10                      4   \n",
       "15                 50                       2                      3   \n",
       "16                 20                       3                      4   \n",
       "17                100                      10                      1   \n",
       "18                 10                       3                      4   \n",
       "19                 60                       2                      3   \n",
       "20                 70                      10                      3   \n",
       "21                100                       2                      4   \n",
       "22                 20                      10                      4   \n",
       "23                 20                       3                      1   \n",
       "24                 20                       5                      2   \n",
       "\n",
       "   param_max_features param_max_depth param_bootstrap  \\\n",
       "0                sqrt             110           False   \n",
       "1                sqrt            None           False   \n",
       "2                sqrt              30            True   \n",
       "3                sqrt              50           False   \n",
       "4                auto              50           False   \n",
       "5                auto              50           False   \n",
       "6                sqrt            None            True   \n",
       "7                sqrt             100            True   \n",
       "8                sqrt              60           False   \n",
       "9                sqrt              80           False   \n",
       "10               auto              20            True   \n",
       "11               sqrt              50           False   \n",
       "12               sqrt              20           False   \n",
       "13               auto              60           False   \n",
       "14               auto              80           False   \n",
       "15               sqrt             110            True   \n",
       "16               sqrt             100            True   \n",
       "17               auto             100            True   \n",
       "18               auto              10            True   \n",
       "19               auto              60            True   \n",
       "20               auto            None           False   \n",
       "21               auto              30            True   \n",
       "22               auto              80            True   \n",
       "23               sqrt              60           False   \n",
       "24               sqrt            None           False   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'n_estimators': 10, 'min_samples_split': 10, ...           0.781649   \n",
       "1   {'n_estimators': 40, 'min_samples_split': 2, '...           0.784933   \n",
       "2   {'n_estimators': 10, 'min_samples_split': 5, '...           0.694055   \n",
       "3   {'n_estimators': 10, 'min_samples_split': 10, ...           0.767598   \n",
       "4   {'n_estimators': 70, 'min_samples_split': 5, '...           0.784276   \n",
       "5   {'n_estimators': 20, 'min_samples_split': 10, ...           0.781255   \n",
       "6   {'n_estimators': 30, 'min_samples_split': 3, '...           0.784101   \n",
       "7   {'n_estimators': 30, 'min_samples_split': 3, '...           0.781212   \n",
       "8   {'n_estimators': 50, 'min_samples_split': 3, '...           0.783225   \n",
       "9   {'n_estimators': 60, 'min_samples_split': 5, '...           0.783926   \n",
       "10  {'n_estimators': 70, 'min_samples_split': 5, '...           0.708151   \n",
       "11  {'n_estimators': 50, 'min_samples_split': 3, '...           0.785151   \n",
       "12  {'n_estimators': 70, 'min_samples_split': 5, '...           0.745229   \n",
       "13  {'n_estimators': 90, 'min_samples_split': 3, '...           0.787034   \n",
       "14  {'n_estimators': 20, 'min_samples_split': 10, ...           0.782394   \n",
       "15  {'n_estimators': 50, 'min_samples_split': 2, '...           0.783751   \n",
       "16  {'n_estimators': 20, 'min_samples_split': 3, '...           0.764052   \n",
       "17  {'n_estimators': 100, 'min_samples_split': 10,...           0.788347   \n",
       "18  {'n_estimators': 10, 'min_samples_split': 3, '...           0.554019   \n",
       "19  {'n_estimators': 60, 'min_samples_split': 2, '...           0.783619   \n",
       "20  {'n_estimators': 70, 'min_samples_split': 10, ...           0.784976   \n",
       "21  {'n_estimators': 100, 'min_samples_split': 2, ...           0.756216   \n",
       "22  {'n_estimators': 20, 'min_samples_split': 10, ...           0.761863   \n",
       "23  {'n_estimators': 20, 'min_samples_split': 3, '...           0.783926   \n",
       "24  {'n_estimators': 20, 'min_samples_split': 5, '...           0.781649   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.786202           0.787559           0.784485   \n",
       "1            0.786684           0.788697           0.785448   \n",
       "2            0.689590           0.689109           0.694129   \n",
       "3            0.763264           0.767554           0.768901   \n",
       "4            0.786640           0.786333           0.787112   \n",
       "5            0.782087           0.788697           0.786543   \n",
       "6            0.779942           0.783970           0.781990   \n",
       "7            0.782481           0.786902           0.783654   \n",
       "8            0.788172           0.789135           0.787287   \n",
       "9            0.785064           0.789398           0.785186   \n",
       "10           0.717606           0.716424           0.710852   \n",
       "11           0.785108           0.789135           0.786105   \n",
       "12           0.743302           0.743171           0.744998   \n",
       "13           0.785151           0.795045           0.791402   \n",
       "14           0.781606           0.785064           0.784223   \n",
       "15           0.789441           0.788960           0.787287   \n",
       "16           0.765278           0.770749           0.767281   \n",
       "17           0.780993           0.790142           0.790089   \n",
       "18           0.545088           0.552399           0.552073   \n",
       "19           0.780424           0.787909           0.783654   \n",
       "20           0.784539           0.789879           0.786280   \n",
       "21           0.763133           0.764971           0.762072   \n",
       "22           0.758405           0.768604           0.763954   \n",
       "23           0.783444           0.787515           0.782253   \n",
       "24           0.785764           0.787209           0.782209   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \\\n",
       "0            0.776387         0.783257        0.003962               15   \n",
       "1            0.779845         0.785121        0.002940                9   \n",
       "2            0.693823         0.692141        0.002287               24   \n",
       "3            0.766187         0.766701        0.001921               19   \n",
       "4            0.785142         0.785901        0.001041                5   \n",
       "5            0.780458         0.783808        0.003228               12   \n",
       "6            0.780108         0.782022        0.001795               17   \n",
       "7            0.781509         0.783152        0.002061               16   \n",
       "8            0.784573         0.786478        0.002227                3   \n",
       "9            0.784267         0.785568        0.001973                8   \n",
       "10           0.707700         0.712147        0.004136               23   \n",
       "11           0.783172         0.785734        0.001949                6   \n",
       "12           0.743641         0.744068        0.000870               22   \n",
       "13           0.786674         0.789061        0.003644                1   \n",
       "14           0.789388         0.784535        0.002724               11   \n",
       "15           0.778663         0.785620        0.004011                7   \n",
       "16           0.768069         0.767086        0.002320               18   \n",
       "17           0.784223         0.786759        0.003598                2   \n",
       "18           0.541698         0.549055        0.004791               25   \n",
       "19           0.781202         0.783362        0.002613               13   \n",
       "20           0.786543         0.786443        0.001877                4   \n",
       "21           0.756599         0.760598        0.003547               21   \n",
       "22           0.759095         0.762384        0.003690               20   \n",
       "23           0.787944         0.785016        0.002285               10   \n",
       "24           0.779845         0.783335        0.002728               14   \n",
       "\n",
       "    split0_train_score  split1_train_score  split2_train_score  \\\n",
       "0             0.997395            0.997176            0.997231   \n",
       "1             1.000000            1.000000            1.000000   \n",
       "2             0.840939            0.832086            0.825705   \n",
       "3             0.969324            0.964104            0.959792   \n",
       "4             0.999934            0.999902            0.999934   \n",
       "5             0.995163            0.992733            0.994419   \n",
       "6             0.992361            0.993226            0.992525   \n",
       "7             0.998293            0.998369            0.998337   \n",
       "8             0.999573            0.999639            0.999661   \n",
       "9             1.000000            1.000000            1.000000   \n",
       "10            0.865410            0.869164            0.865968   \n",
       "11            1.000000            0.999978            0.999978   \n",
       "12            0.923545            0.918631            0.920907   \n",
       "13            0.999956            0.999978            0.999978   \n",
       "14            0.997001            0.996443            0.996826   \n",
       "15            0.998468            0.998347            0.998238   \n",
       "16            0.967015            0.968022            0.967398   \n",
       "17            1.000000            1.000000            1.000000   \n",
       "18            0.589347            0.584214            0.584860   \n",
       "19            0.996640            0.995666            0.996279   \n",
       "20            1.000000            1.000000            1.000000   \n",
       "21            0.954976            0.950139            0.951332   \n",
       "22            0.960087            0.959879            0.958019   \n",
       "23            1.000000            1.000000            1.000000   \n",
       "24            1.000000            1.000000            1.000000   \n",
       "\n",
       "    split3_train_score  split4_train_score  mean_train_score  std_train_score  \n",
       "0             0.997538            0.997341          0.997336         0.000127  \n",
       "1             1.000000            1.000000          1.000000         0.000000  \n",
       "2             0.838096            0.841707          0.835707         0.006037  \n",
       "3             0.966227            0.966194          0.965128         0.003146  \n",
       "4             0.999945            0.999869          0.999917         0.000028  \n",
       "5             0.995272            0.994462          0.994410         0.000908  \n",
       "6             0.992777            0.992810          0.992740         0.000294  \n",
       "7             0.998161            0.998304          0.998293         0.000071  \n",
       "8             0.999628            0.999661          0.999632         0.000032  \n",
       "9             1.000000            1.000000          1.000000         0.000000  \n",
       "10            0.864394            0.862599          0.865507         0.002158  \n",
       "11            0.999989            0.999989          0.999987         0.000008  \n",
       "12            0.924761            0.917680          0.921105         0.002728  \n",
       "13            1.000000            0.999978          0.999978         0.000014  \n",
       "14            0.996969            0.996465          0.996741         0.000242  \n",
       "15            0.998490            0.998337          0.998376         0.000093  \n",
       "16            0.966731            0.967551          0.967343         0.000445  \n",
       "17            1.000000            1.000000          1.000000         0.000000  \n",
       "18            0.580815            0.575103          0.582868         0.004739  \n",
       "19            0.996651            0.996104          0.996268         0.000367  \n",
       "20            1.000000            1.000000          1.000000         0.000000  \n",
       "21            0.952109            0.951234          0.951958         0.001634  \n",
       "22            0.960668            0.961007          0.959932         0.001038  \n",
       "23            0.999989            1.000000          0.999998         0.000004  \n",
       "24            1.000000            1.000000          1.000000         0.000000  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_predict = rf_rand_cv_25.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Fail       0.82      0.82      0.82     14336\n",
      "        Win       0.82      0.82      0.82     14219\n",
      "\n",
      "avg / total       0.82      0.82      0.82     28555\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, rf_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROC Cuve\n",
    "y_pred_prob = rf_rand_cv_25.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob, pos_label='Win')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf6 = RandomForestClassifier(bootstrap=True,\n",
    "                                max_depth=60, max_features='auto',\n",
    "                                min_samples_leaf=4, min_samples_split=3,\n",
    "                                n_estimators=90)\n",
    "\n",
    "rf5_cv_score = cross_val_score(rf6, X, red_win, cv=5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92547976 0.95829102 0.86579814 0.66106325 0.67388107]\n"
     ]
    }
   ],
   "source": [
    "print(rf5_cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8169026458602264"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(rf5_cv_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Out of the box logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgc = LogisticRegression()\n",
    "lgc_X_train, lgc_X_test, lgc_y_train, lgc_y_test = train_test_split(X, red_win, test_size=0.2, random_state=42)\n",
    "lgc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5657152862896165"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test score\n",
    "lgc.score(lgc_X_test, lgc_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_lgc = lgc.predict(lgc_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Fail       0.57      0.56      0.57     14336\n",
      "        Win       0.56      0.57      0.57     14219\n",
      "\n",
      "avg / total       0.57      0.57      0.57     28555\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(lgc_y_test, predict_lgc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test different values of C hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lg_param_grid = {'C': [0.001, 0.01, 0.1, 10, 100, 1000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lgc2 = LogisticRegression()\n",
    "lgc_cv = GridSearchCV(lgc2, lg_param_grid, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [0.001, 0.01, 0.1, 10, 100, 1000]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgc_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.1}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgc_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5612688017650458"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgc_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_lgc_cv = lgc_cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Fail       0.57      0.57      0.57     14336\n",
      "        Win       0.56      0.57      0.57     14219\n",
      "\n",
      "avg / total       0.57      0.57      0.57     28555\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predict_lgc_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Nearest Neighbors Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Out of the box KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn_X_train, knn_X_test, knn_y_train, knn_y_test = train_test_split(X, red_win, test_size=0.2, random_state=42)\n",
    "knn.fit(knn_X_train, knn_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn.score(knn_X_test, knn_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_knn = knn.predict(knn_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(knn_y_test, predict_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Support Vector Machine Classifier Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Out of the box SVC model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "steps = [('scaler', StandardScaler()),\n",
    "        ('svm', SVC(C=0.001, cache_size=1000.0))]\n",
    "\n",
    "pl = Pipeline(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('svm', SVC(C=0.001, cache_size=1000.0, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False))])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.fit(X_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50525"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.score(X_test2, y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm_predict = pl.predict(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Fail       0.51      1.00      0.67      2021\n",
      "        Win       0.00      0.00      0.00      1979\n",
      "\n",
      "avg / total       0.26      0.51      0.34      4000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jltsa\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test2, svm_predict))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Process\n",
    "\n",
    "#Create a pipeline\n",
    "steps = [('scaler', StandardScaler()),\n",
    " ('knn', KNeighborsClassifier())]\n",
    " \n",
    " pl = Pipeline(steps)\n",
    " \n",
    " #Specify hyper parameters\n",
    " parameters = {'SVM__C':[1, 10, 100],\n",
    "              'SVM__gamma':[0.1, 0.01]}\n",
    "              \n",
    " #create test and training sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, testsize=0.2, random_state=42)\n",
    " \n",
    " #Gridsearch\n",
    " cv = GridSearchCV(pl, param_grid=parameters)\n",
    " \n",
    " #fit\n",
    " cv.fit(X_train, y_train)\n",
    " \n",
    " y_pred = cv.predict(X_test)\n",
    " \n",
    " #Compute metrics\n",
    " cv.classification_report(y_test, y_pred)\n",
    " cv.best_params_\n",
    " cv.score(X_test, y_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
